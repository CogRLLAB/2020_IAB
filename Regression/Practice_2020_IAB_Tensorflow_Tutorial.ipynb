{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "ATARI_kernel",
      "language": "python",
      "name": "atari_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Tensorflow_tutorial_0410.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMEBf__74wrF",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow 튜토리얼 - IAB 04/10\n",
        "\n",
        "## - Basics of Tensorflow -\n",
        "\n",
        "\n",
        "written by Jeonho Park, Kyundo Kim (RLLAB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-RD_d3r4wrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################# Tensorflow Installation ##################\n",
        "# By default, \"Google Colaboratory\" offers Tensorflow with version 2.1.\n",
        "# Since our code is based on Tensorflow version 1.x,  we will first install the right version of it.\n",
        "\n",
        "!pip install tensorflow==1.14.0 \n",
        "import tensorflow as tf\n",
        "print(\"Current version is\", tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RUqhh8L4wrV",
        "colab_type": "text"
      },
      "source": [
        "# **Tensorflow Graph Construction & Graph Execution  & Optimization**\n",
        "* Tensorflow에서 Graph란 우리가 정의하는 여러가지 **값(value)들과 각종 연산(operation)들이 서로 연결되어 이루는 모임**입니다.\n",
        "\n",
        "* Tensorflow에서는 **그 Graph라는 것을 구성하는 과정**과 **만들어진 Graph를 실제로 실행시키는 과정** 이 서로 분리되어 있습니다.\n",
        "\n",
        "* Graph의 구성 요소들 중에서 가장 기본적인 것 중 하나인 **tf.constant**부터 시작해보겠습니다.\n",
        "\n",
        "\n",
        "## Step 1 : tf.constant() 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYn5X4QV4wrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이전에 구성해놓았던 graph가 있었다면 모두 리셋됩니다.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# tf.constant(숫자나 텐서, dtype=데이터 타입): 말 그대로 상수(constant)를 graph 안에 만들 수 있습니다. \n",
        "# 상수로 이루어진 벡터, 행렬, 텐서 또한 만들 수 있습니다.\n",
        "c1 = tf.constant(3, dtype=tf.int32)\n",
        "c2 = tf.constant(12.7, dtype=tf.float32)\n",
        "\n",
        "arr1 = tf.constant([[1., 2.], [3., 4.]], dtype=tf.float32)\n",
        "arr2 = tf.constant(1., shape=(2,3), dtype=tf.float32)\n",
        "\n",
        "# 만들어 놓은 tf.constant들을 그대로 출력해봅시다.\n",
        "print(\"c1:  \", c1)\n",
        "print(\"c2:  \", c2)\n",
        "print(\"arr1:\", arr1)\n",
        "print(\"arr2:\", arr2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM8Ak6Gl4wra",
        "colab_type": "text"
      },
      "source": [
        "## Step 2 : tf.Session() 구성하기 - Graph Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1N230w04wrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 새로운 session을 정의합니다.\n",
        "sess = tf.Session()\n",
        "\n",
        "# 앞에서 정의했던 tf.constant들을 session을 이용하여 실제로 실행시킵니다.\n",
        "c1_result = sess.run(c1)\n",
        "c2_result = sess.run(c2)\n",
        "arr1_result = sess.run(arr1)\n",
        "arr2_result = sess.run(arr2)\n",
        "\n",
        "# 실행 결과를 출력해봅시다.\n",
        "print('c1_result:', c1_result)\n",
        "print('c2_result:', c2_result)\n",
        "print('arr1_result:\\n', arr1_result)\n",
        "print('arr2_result:\\n', arr2_result)\n",
        "\n",
        "# session을 닫습니다. \n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2roeSSaU3NCX",
        "colab_type": "text"
      },
      "source": [
        "## Step 3 : Basic Operations 실행해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_3B-ew7K4wrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# Basic Tensorflow Operations\n",
        "\n",
        "mat1 = tf.constant([[1., 2.], [3., 4.]], dtype=tf.float32)\n",
        "mat2 = tf.constant([[1, 0.1], [0.01, 0.001]], dtype=tf.float32)\n",
        "sess = tf.Session()\n",
        "\n",
        "# Adding : tf.add()\n",
        "plus_operation = tf.add(mat1,mat2) # element-wise addtion\n",
        "plus_result = sess.run(plus_operation)\n",
        "\n",
        "print('mat1:\\n', sess.run(mat1))\n",
        "print('mat2:\\n', sess.run(mat2))\n",
        "print('\\n# result of \"tf.add\":\\n', plus_result)\n",
        "\n",
        "# Multiplication : (tf.matmul() vs. tf.multiply()) \n",
        "matmul_operation = tf.matmul(mat1, mat2)  # matrix multiplication (행렬곱셈)\n",
        "multiply_operation = tf.multiply(mat1, mat2) # element-wise multiplication (원소간 곱셈)\n",
        "matmul_result, multiply_result = sess.run([matmul_operation, multiply_operation])\n",
        "\n",
        "print('\\n\"tf.matmul\" 와 \"tf.multiply\"의 결과를 비교해봅니다. ')\n",
        "print('# result of tf.matmul:\\n', matmul_result)\n",
        "print('# result of tf.multiply:\\n', multiply_result)\n",
        "\n",
        "# Summation : tf.reduce_sum(텐서, axis=summation으로 인해 없어질(reduce) axis)\n",
        "summation_operation = tf.reduce_sum(mat1, axis=1)\n",
        "\n",
        "print('\\n# result of tf.reduce_sum:\\n', sess.run(summation_operation))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFLO_3SF3eWX",
        "colab_type": "text"
      },
      "source": [
        "## Step 4-1 : Variables 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "H2WeFG084wrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Variable 정의하기 (\"tf.Variable\" vs. \"tf.get_variable()\")\n",
        "# 방법1: tf.Variable(값, dtype=데이터타입)\n",
        "# 방법2: tf.get_variable(\"tf graph 상에서의 이름\", shape=변수의 구조( ex: n by m->(n,m)), initializer=어떤 방식의 initialization을 적용할 것인지 )\n",
        "var1 = tf.Variable([[1.,2.,3.],[4.,5.,6.]], dtype=tf.float32)                                                                   \n",
        "var2 = tf.get_variable('var2', shape=(2,3), initializer=tf.random_normal_initializer(), dtype=tf.float32)\n",
        "var1_plus_var2 = tf.add(var1, var2)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "# session을 실행시켜서 만들어놓은 variable들을 출력시켜 봅시다.  \n",
        "# variable 값들 대신 \"Attempting to use uninitialized value Variable\" 라는 에러가 출력됩니다.\n",
        "print('var1: \\n', sess.run(var1))\n",
        "print('var2: \\n', sess.run(var2))\n",
        "print('var1 + var2: \\n', sess.run(var1_plus_var2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxPGsbfH3YIC",
        "colab_type": "text"
      },
      "source": [
        "## Step 4-2 : Variable Initialization 해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsS2cR4p4wrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "var1 = tf.Variable([[1.,2.,3.],[4.,5.,6.]], dtype=tf.float32)\n",
        "var2 = tf.get_variable('var2', shape=(2,3), initializer=tf.random_normal_initializer(), dtype=tf.float32)\n",
        "var1_plus_var2 = tf.add(var1, var2)\n",
        "sess = tf.Session()\n",
        "\n",
        "# Variable을 출력하기 전에 먼저 Variable Initializer를 정의하고, 실행시킵니다.\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "# Variable들을 sess.run()으로 실행시킨 후 다시 출력시켜봅시다.\n",
        "print('var1: \\n', sess.run(var1))\n",
        "print('var2: \\n', sess.run(var2))\n",
        "print('var1 + var2: \\n', sess.run(var1_plus_var2))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq02KFP9oA9V",
        "colab_type": "text"
      },
      "source": [
        "## **Self-Check Problem 1**\n",
        "1. 모든 값이 2.0으로 채워진 2 * 3 * 4 크기의 constant 텐서를 **\"A\"**로 정의해보세요.\n",
        "\n",
        "2. 마찬가지로 2 * 3 * 4 크기이며 tf.glorot_normal_initializer()라는 initializer를 사용하는 variable을 **\"B\"**로 정의해보세요. (dtype은 tf.float32로)\n",
        "\n",
        "3. A와 B 간의 element-wise multiplication을 수행하는 operation을 만들어서 **\"AB_mul\"**에 저장해보세요.\n",
        "\n",
        "4. 세션을 만들고, variable initialization을 수행한 뒤, AB_mul을 실행하여 그 값을 **\"RESULT\"**에 저장해보세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yozgGJ_bvF3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# Q1. \n",
        "A = \n",
        "\n",
        "# Q2.\n",
        "B = \n",
        "\n",
        "# Q3.\n",
        "AB_mul = \n",
        "\n",
        "# Q4.\n",
        "\n",
        "RESULT = \n",
        "print('The Result is:\\n', RESULT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvXq8LuIvGuE",
        "colab_type": "text"
      },
      "source": [
        "## Step 5-1 : tf.placeholder() 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVY2WXur4wrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# placeholder를 정의합니다.\n",
        "ph1 = tf.placeholder(tf.int32, shape=(1,2))\n",
        "\n",
        "c1 = tf.Variable([[1,2]], dtype=tf.int32)\n",
        "ph1_plus_c1 = tf.add(ph1, c1)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "# placeholder에 들어가게 될 feed_dict를 정의합니다.\n",
        "feed_dict = {ph1:[[2,3]]}\n",
        "\n",
        "# placeholder에 feed_dict을 넣고 graph를 실행시켜 봅니다.\n",
        "result = sess.run(ph1_plus_c1, feed_dict=feed_dict)\n",
        "print(\"result is\", result)\n",
        "\n",
        "sess.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFSyBuMj3uE1",
        "colab_type": "text"
      },
      "source": [
        "## Step 5-2 : Example of using tf.placeholder() in Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLz3-67o4wr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# input_data - network에 들어가게 되는 input입니다.\n",
        "input_data = tf.placeholder(tf.float32, shape=(2,2))\n",
        "\n",
        "# Tensorflow를 사용하면 MLP network를 다음과 같이 만들 수 있습니다. \n",
        "MLP_layer1 = tf.layers.dense(inputs=input_data, units=64, activation=tf.nn.sigmoid, kernel_initializer=tf.random_normal_initializer())\n",
        "MLP_layer2 = tf.layers.dense(inputs=MLP_layer1, units=64, activation=tf.nn.sigmoid, kernel_initializer=tf.random_normal_initializer())\n",
        "# network output\n",
        "output =  tf.layers.dense(inputs=MLP_layer2, units=1, activation=tf.nn.sigmoid, kernel_initializer=tf.random_normal_initializer())\n",
        "\n",
        "# session 구성과 variable initialization\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "# network output을 다음과 같이 출력할 수 있습니다.\n",
        "feed_dict={input_data:[[1.,2.],[3.,4.]]}\n",
        "result = sess.run(output, feed_dict=feed_dict)\n",
        "print('#####################')\n",
        "print('network output is: \\n', result)\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIzQ2M3P3-dj",
        "colab_type": "text"
      },
      "source": [
        "## Step 6 : How to conduct Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YXe_rdc4wr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "tf.reset_default_graph()\n",
        "\n",
        "# \"tf.constant()\"로 고정된 값 target과 train이 가능한 \"variable\"인 parameter를 정의합니다.\n",
        "target = tf.constant(3.0, dtype=tf.float32)\n",
        "parameter = tf.get_variable('w', shape=(), dtype=tf.float32, initializer=tf.random_normal_initializer())\n",
        "\n",
        "# Loss는 target과 parameter 값의 차이의 제곱으로 설정합니다.\n",
        "loss = tf.square(target - parameter)\n",
        "\n",
        "# Optimizer를 정의하고, loss를 줄이는 operation을 생성합니다.\n",
        "optimizer= tf.train.GradientDescentOptimizer(learning_rate=1e-1)\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "# training을 진행하면서 매 step마다 parameter와 loss의 값이 어떻게 바뀌는지 출력합니다.\n",
        "print('initial value of \"parameter\"', sess.run(parameter))\n",
        "time.sleep(0.5) # 0.5초 동안 코드 실행을 멈춥니다.\n",
        "for step in range(30):\n",
        "  sess.run(train)\n",
        "  intermediate_result = sess.run(parameter)\n",
        "  intermediate_loss = sess.run(loss)\n",
        "  time.sleep(0.5)\n",
        "  print('step:', step, 'parameter:', intermediate_result, 'loss:', intermediate_loss)\n",
        "\n",
        "trained_parameter = sess.run(parameter)\n",
        "print('TRAINING FINNISHED.')\n",
        "print('Final value of parameter: ', trained_parameter)\n",
        "print('Final value of target:        ', sess.run(target))\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0GF3hci2iDM",
        "colab_type": "text"
      },
      "source": [
        "## Self-Check Problem 2\n",
        "1. 데이터 형식은 tf.float32이고 [a1, a2, a3]와 같은 shape을 가지는 **TARGET_ph**를 정의해보세요. \n",
        "\n",
        "2. TARGET_ph와 shape이 같고, tf.random_normal_initializer()라는 initializer를 사용하는 variable인 **PARAMETERS**를 정의해보세요.\n",
        "\n",
        "3. SQUARED의 각 성분들을 모두 합한 값을 **LOSS** 로 정의해보세요.\n",
        "\n",
        "4. LOSS를 줄이는 방향으로 training될 수 있도록 **OPTIMIZER**와 **TRAIN**을 설정해보세요.\n",
        "\n",
        "5. TARGET_ph의 값을 [1.0, 2.0, 3.0] 으로 feed해주고, 100step 동안 PARAMETERS를 training 시켜보세요. PARAMETERS의 값이 TARGET_ph와 비슷해졌는지 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1PvLSuj4wr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# Q1.\n",
        "TARGET_ph = \n",
        "\n",
        "# Q2.\n",
        "PARAMETERS = \n",
        "\n",
        "# Q3.\n",
        "SQUARED = tf.square(TARGET_ph - PARAMETERS)\n",
        "LOSS  = \n",
        "\n",
        "# Q4.\n",
        "OPTIMIZER = \n",
        "TRAIN = \n",
        "\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "print('initial values of \"PARAMETER\"', sess.run(PARAMETERS))\n",
        "for step in range(100):\n",
        "  # Q5.\n",
        "\n",
        "\n",
        "trained_PARAMETERS = sess.run(PARAMETERS)\n",
        "print('TRAINING FINNISHED.')\n",
        "print('Final values of PARAMETERS: ', trained_PARAMETERS)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXo1eRjN67QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}