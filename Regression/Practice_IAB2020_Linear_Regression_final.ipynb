{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "Linear_Regression.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWjZwpZ3DEDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7wBAGu-EZN3t",
        "colab": {}
      },
      "source": [
        "################# Tensorflow Installation ##################\n",
        "# By default, \"Google Colaboratory\" offers Tensorflow with version 2.1.\n",
        "# Since our code is based on Tensorflow version 1.x,  we will first install the right version of it.\n",
        "\n",
        "!pip install tensorflow==1.14.0\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3o-pTWFDEDc",
        "colab_type": "text"
      },
      "source": [
        "# **TOPIC : Linear Regression**\n",
        "\n",
        "#### In this exercise, we are going to cover some basic implementations of Linear Regression.\n",
        "* Univariate(1-dimension) linear regression\n",
        "* Multivariate(2-dimension) linear regression\n",
        "* _(Additional)_ General linear regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42pcH9loDEDd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "## **Univariate Linear Regression**\n",
        "\n",
        "## 1. Generate a 1-D example data set\n",
        "----- Here, we will make our own data set, which will be used for testing our algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyIK0H5UDEDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a simple linear function\n",
        "def f1(x,a,b):\n",
        "    return a*x+b\n",
        "\n",
        "a = 5.\n",
        "b = 3.\n",
        "\n",
        "x = np.linspace(-1,1,100)\n",
        "y = f1(x,a,b)\n",
        "\n",
        "n = 10\n",
        "x_data = np.linspace(-1,1,n)\n",
        "y_data = f1(x_data,a,b) + np.random.randn(n)  # we will insert some noise into y_data\n",
        "\n",
        "plt.plot(x,y,\"k-\",label=\"Ground Truth\")\n",
        "plt.plot(x_data,y_data,\"r.\",label=\"Data\")\n",
        "plt.legend()\n",
        "plt.xlim([-1,1])\n",
        "plt.ylim([-2,8])\n",
        "plt.xlabel('x_data')\n",
        "plt.ylabel('y_data')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2HXW7P8DEDi",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tensorflow Graph Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56W-C7CdDEDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# placeholder for x, y data\n",
        "x_ph = (A)\n",
        "y_ph = (B)\n",
        "\n",
        "# estimation of true \"a\" and \"b\"\n",
        "a_hat = (C)\n",
        "b_hat = (D)\n",
        "\n",
        "# prediction of y\n",
        "y_pred = (E)\n",
        "\n",
        "# define loss function\n",
        "loss = (F)\n",
        "\n",
        "# define optimizer\n",
        "optimizer = (G) \n",
        "train = (H)\n",
        "\n",
        "print(\"Tensorflow graph is constructed!!!\")\n",
        "print(\"x_ph is:\")\n",
        "print(\"type: \"+str(type(x_ph)))\n",
        "print(\"shape: \"+str(x_ph.shape))\n",
        "print(\"a_hat is:\")\n",
        "print(\"type: \"+str(type(a_hat)))\n",
        "print(\"shape: \"+str(a_hat.shape))\n",
        "print(\"y_pred is:\")\n",
        "print(\"type: \"+str(type(y_pred)))\n",
        "print(\"shape: \"+str(y_pred.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO_ZAKYYbpGf",
        "colab_type": "text"
      },
      "source": [
        "(A) x_ph = tf.placeholder(tf.float32,shape=(None,))\n",
        "\n",
        "(B) y_ph = tf.placeholder(tf.float32,shape=(None,))\n",
        "\n",
        "(C) a_hat = tf.get_variable(\"a\",shape=(),initializer=tf.random_normal_initializer())\n",
        "\n",
        "(D) b_hat = tf.get_variable(\"b\",shape=(),initializer=tf.random_normal_initializer())\n",
        "\n",
        "(E) y_pred = tf.multiply(x_ph,a_hat) + b_hat\n",
        "\n",
        "(F) loss = 0.5 * tf.reduce_mean( tf.square(y_pred - y_ph) )\n",
        "\n",
        "(G) optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "\n",
        "(H) train = optimizer.minimize(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MRJYV9YDEDn",
        "colab_type": "text"
      },
      "source": [
        "## 3. Initialize TF variables\n",
        "---- Before we start the training, first we have to initialize TF variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJZqcT3kDEDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize variables\n",
        "init = (A)\n",
        "\n",
        "sess = (B)\n",
        "sess.run(init)\n",
        "\n",
        "a_np, b_np = sess.run([a_hat,b_hat])\n",
        "\n",
        "# let's see how a and b got initialized\n",
        "print(\"Randomly initialized parameters\")\n",
        "print(\"a: %f\"%a_np)\n",
        "print(\"b: %f\"%b_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-iLYeyUcS-1",
        "colab_type": "text"
      },
      "source": [
        "(A) init = tf.global_variables_initializer()\n",
        "\n",
        "(B) sess = tf.Session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anVbdo0JDEDr",
        "colab_type": "text"
      },
      "source": [
        "## 4. Training\n",
        "---- Optimizer will find the best parameters for our linear model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls3ky6I4DEDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nepoch = 3000\n",
        "feed_dict = (A)\n",
        "for epoch in range(nepoch):\n",
        "    loss_np,_ = (B)\n",
        "    if (epoch%300) == 0:\n",
        "        print(\"[%d/%d] loss : %f\"%(epoch,nepoch,loss_np))\n",
        "print()\n",
        "    \n",
        "a_np, b_np = sess.run([a_hat,b_hat])\n",
        "\n",
        "# let's see the final results of our training\n",
        "print(\"Optimized parameters\")\n",
        "print(\"a: %f\"%a_np)\n",
        "print(\"b: %f\\n\"%b_np)\n",
        "print(\"Original parameters\")\n",
        "print(\"a: %f\"%a)\n",
        "print(\"b: %f\"%b)\n",
        "\n",
        "feed_dict = {x_ph:x}\n",
        "y_pred_np = sess.run(y_pred,feed_dict=feed_dict)\n",
        "plt.plot(x,y,\"k-\",label=\"Ground Truth\")\n",
        "plt.plot(x_data,y_data,\"r.\",label=\"Data\")\n",
        "plt.plot(x,y_pred_np,\"b-\",label=\"Linear Regression\")\n",
        "plt.legend()\n",
        "plt.xlim([-1,1])\n",
        "plt.ylim([-2,8])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8avAt21cg50",
        "colab_type": "text"
      },
      "source": [
        "(A) feed_dict = {x_ph:x_data,y_ph:y_data}\n",
        "\n",
        "(B) loss_np, _ = sess.run([loss,train],feed_dict=feed_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWyG4sfDDEDv",
        "colab_type": "text"
      },
      "source": [
        "# **Multivariate Linear Regression**\n",
        "\n",
        "## 1. Generate a 2-D example data set\n",
        "---- In multivariate case, X data is multi-dimensional (*in this case, 2-D*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txo98lrSDEDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f2(x,a,b):\n",
        "    return np.matmul(x,a)+b\n",
        "\n",
        "a = np.array([[2.],[1.]])\n",
        "b = 1.\n",
        "\n",
        "x1 = np.linspace(-1,1,100)\n",
        "x2 = np.linspace(-1,1,100)\n",
        "X1,X2 = np.meshgrid(x1,x2)\n",
        "x = np.concatenate([np.reshape(X1,[-1,1]),np.reshape(X2,[-1,1])],axis=1)\n",
        "y = f2(x,a,b)\n",
        "Y = np.reshape(y,[100,100])\n",
        "\n",
        "n = 50\n",
        "x_data = np.random.uniform(-1,1,size=(n,2))\n",
        "y_data = f2(x_data,a,b) + np.random.randn(n,1)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection='3d')\n",
        "\n",
        "ax.plot_surface(X1,X2,Y)\n",
        "ax.plot3D(x_data[:,0].flatten(),x_data[:,1].flatten(),y_data.flatten(),'r.',label=\"Data\")\n",
        "plt.legend()\n",
        "ax.set_xlim3d(-1,1)\n",
        "ax.set_ylim3d(-1,1)\n",
        "ax.set_zlim3d(-3,4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DJ40vKJDED0",
        "colab_type": "text"
      },
      "source": [
        "## 2. *(TO DO)* Tensorflow Graph Construction **+** TF Variables Initialization **+** Training !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aTLoxzNDED1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################## TO DO ###########################\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# placeholder for x, y data\n",
        "x_ph = (A)\n",
        "y_ph = (B)\n",
        "\n",
        "# estimation of true \"a\" and \"b\"\n",
        "a_hat = (C) \n",
        "b_hat = (D) \n",
        "\n",
        "# prediction of y\n",
        "y_pred = (E)\n",
        "\n",
        "# define loss function\n",
        "loss = (F)\n",
        "\n",
        "# define optimizer\n",
        "optimizer = (G)\n",
        "train = (H)\n",
        "\n",
        "# initialize variables\n",
        "init = tf.global_variables_initializer()\n",
        "################################################################\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "a_np, b_np = sess.run([a_hat,b_hat])\n",
        "print(\"Randomly initialized parameters\")\n",
        "print(\"a: {:}\".format(a_np.flatten()))\n",
        "print(\"b: %f\\n\"%b_np)\n",
        "\n",
        "############################## TO DO ###########################\n",
        "nepoch = 10000\n",
        "feed_dict = (I)\n",
        "for epoch in range(nepoch):\n",
        "    loss_np,_ = (J)\n",
        "    if (epoch%1000) == 0:\n",
        "        print(\"[%d/%d] loss : %f\"%(epoch,nepoch,loss_np))\n",
        "################################################################\n",
        "\n",
        "a_np, b_np = sess.run([a_hat,b_hat])\n",
        "print(\"Optimized parameters\")\n",
        "print(\"a: {:}\".format(a_np.flatten()))\n",
        "print(\"b: %f\\n\"%b_np)\n",
        "\n",
        "print(\"Original parameters\")\n",
        "print(\"a: {:}\".format(a.flatten()))\n",
        "print(\"b: %f\"%b)\n",
        "\n",
        "feed_dict = {x_ph:x}\n",
        "y_pred_np = sess.run(y_pred,feed_dict=feed_dict)\n",
        "Y_pred_np= np.reshape(y_pred_np,[100,100])\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection='3d')\n",
        "\n",
        "ax.plot_surface(X1,X2,Y,color=\"k\")\n",
        "ax.plot3D(x_data[:,0].flatten(),x_data[:,1].flatten(),y_data.flatten(),'r.',label=\"Data\")\n",
        "plt.legend()\n",
        "ax.set_xlim3d(-1,1)\n",
        "ax.set_ylim3d(-1,1)\n",
        "ax.set_zlim3d(-3,4)\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection='3d')\n",
        "ax.plot_surface(X1,X2,Y_pred_np,color=\"b\")\n",
        "ax.plot3D(x_data[:,0].flatten(),x_data[:,1].flatten(),y_data.flatten(),'r.',label=\"Data\")\n",
        "\n",
        "plt.legend()\n",
        "ax.set_xlim3d(-1,1)\n",
        "ax.set_ylim3d(-1,1)\n",
        "ax.set_zlim3d(-3,4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzrxx5m6ct-Y",
        "colab_type": "text"
      },
      "source": [
        "(A) x_ph = tf.placeholder(tf.float32,shape=(None,2))\n",
        "\n",
        "(B) y_ph = tf.placeholder(tf.float32,shape=(None,1))\n",
        "\n",
        "(C) a_hat = tf.get_variable(\"a\",shape=(2,1),initializer=tf.random_normal_initializer())\n",
        "\n",
        "(D) b_hat = tf.get_variable(\"b\",shape=(),initializer=tf.random_normal_initializer())\n",
        "\n",
        "(E) y_pred = tf.matmul(x_ph,a_hat) + b_hat\n",
        "\n",
        "(F) loss = 0.5 * tf.reduce_mean( tf.square(y_pred - y_ph) )\n",
        "\n",
        "(G) optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "\n",
        "(H) train = optimizer.minimize(loss)\n",
        "\n",
        "(I) feed_dict = {x_ph:x_data,y_ph:y_data}\n",
        "\n",
        "(J) loss_np, _ = sess.run([loss,train],feed_dict=feed_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4q26dTyDED5",
        "colab_type": "text"
      },
      "source": [
        "# **General Linear Regression (Non-linear Regression)**\n",
        "\n",
        "## 1. Generate Non-linear 1-D data \n",
        "---- Here, we will take care of cases when Xs and Ys are **not** in a linear relationship."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecCw0umnDED6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f3(x):\n",
        "    return np.sinc(x)\n",
        "\n",
        "x = np.linspace(-2*np.pi,2*np.pi,100)\n",
        "y = f3(x)\n",
        "\n",
        "n = 500\n",
        "x_data = np.linspace(-2*np.pi,2*np.pi,n) + 0.05*np.random.randn(n)\n",
        "y_data = f3(x_data) + 0.05*np.random.randn(n)\n",
        "\n",
        "plt.plot(x,y,\"k-\",label=\"Ground Truth\")\n",
        "plt.plot(x_data,y_data,\"r.\",label=\"Data\")\n",
        "plt.legend()\n",
        "plt.xlim([-2*np.pi,2*np.pi])\n",
        "plt.ylim([-1,1.5])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4vqejWDDED_",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tensorflow Graph Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuMS6pEbDEEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "n_kernel = 20\n",
        "mu = np.linspace(-2*np.pi,2*np.pi,n_kernel)\n",
        "inv_squared_s = 1e1\n",
        "\n",
        "# placeholder for x, y data\n",
        "x_ph = (A)\n",
        "y_ph = (B) \n",
        "\n",
        "# placeholder for mu and s\n",
        "mu_ph = (C) \n",
        "inv_squared_s_ph = (D) \n",
        "\n",
        "# estimation of parameters \"w\"\n",
        "w_hat = (E)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGzLmFgpd01t",
        "colab_type": "text"
      },
      "source": [
        "(A) tf.placeholder(tf.float32,shape=(None,1))\n",
        "\n",
        "(B) tf.placeholder(tf.float32,shape=(None,1))\n",
        "\n",
        "(C) mu_ph = tf.placeholder(tf.float32,shape=(n_kernel,1))\n",
        "\n",
        "(D) inv_squared_s_ph = tf.placeholder(tf.float32,shape=())\n",
        "\n",
        "(E) w_hat = tf.get_variable(\"w\",shape=(n_kernel+1,1),initializer=tf.random_normal_initializer())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk-pTg8ADEEG",
        "colab_type": "text"
      },
      "source": [
        "## 3. Define Distance Matrix $D$\n",
        "\n",
        "$X^2 - 2X\\mu^{t} + \\mu^{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDp3_YujDEEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_norm = (A) \n",
        "mu_norm = (B) \n",
        "\n",
        "x_norm = (C) \n",
        "mu_norm = (D) \n",
        "\n",
        "squared_dist = (E) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XD4VIKheSRS",
        "colab_type": "text"
      },
      "source": [
        "(A) x_norm = tf.reduce_sum(tf.square(x_ph), axis=1)\n",
        "\n",
        "(B) mu_norm = tf.reduce_sum(tf.square(mu_ph), axis=1)\n",
        "\n",
        "(C) x_norm = tf.reshape(x_norm, [-1, 1])\n",
        "\n",
        "(D) mu_norm = tf.reshape(mu_norm, [1, -1])\n",
        "\n",
        "(E) squared_dist = x_norm - 2 * tf.matmul(x_ph, mu_ph, False, True) + mu_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TsNNrvFDEEM",
        "colab_type": "text"
      },
      "source": [
        "## 4. Define Regressor and Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC6JktaCDEEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel = (A)\n",
        "kernel = (B)\n",
        "\n",
        "y_pred = tf.matmul(kernel,w_hat)\n",
        "\n",
        "loss = 0.5 * tf.reduce_mean( tf.square(y_pred - y_ph) )\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "train = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phoF4NI4ehq-",
        "colab_type": "text"
      },
      "source": [
        "(A) kernel = tf.exp(-inv_squared_s_ph * 0.5 * squared_dist)\n",
        "\n",
        "(B) kernel = tf.concat([kernel, tf.ones_like(x_ph)],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d4_3tOEDEEP",
        "colab_type": "text"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2rZ3URLDEEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "w_np = sess.run(w_hat)\n",
        "print(\"Randomly initialized parameters\")\n",
        "print(\"w: {:}\\n\".format(w_np.flatten()))\n",
        "\n",
        "nepoch = 10000\n",
        "feed_dict = {x_ph:x_data[:,np.newaxis],y_ph:y_data[:,np.newaxis],mu_ph:mu[:,np.newaxis],inv_squared_s_ph:inv_squared_s}\n",
        "\n",
        "for epoch in range(nepoch):\n",
        "    loss_np,_ = sess.run([loss,train],feed_dict=feed_dict)\n",
        "    if (epoch%1000) == 0:\n",
        "        print(\"[%d/%d] loss : %f\"%(epoch,nepoch,loss_np))\n",
        "\n",
        "w_np = sess.run(w_hat)\n",
        "print(\"\\nOptimized parameters\")\n",
        "print(\"w: {:}\".format(w_np.flatten()))\n",
        "\n",
        "feed_dict = {x_ph:x[:,np.newaxis],mu_ph:mu[:,np.newaxis],inv_squared_s_ph:inv_squared_s}\n",
        "y_pred_np = sess.run(y_pred,feed_dict=feed_dict)\n",
        "\n",
        "plt.plot(x,y,\"k-\",label=\"Ground Truth\")\n",
        "plt.plot(x_data,y_data,\"r.\",label=\"Data\")\n",
        "plt.plot(x,y_pred_np,\"b-\",label=\"Kernel Regression\")\n",
        "plt.legend()\n",
        "# plt.title('')\n",
        "plt.xlim([-2*np.pi,2*np.pi])\n",
        "plt.ylim([-1,1.5])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnLgxNcWghtF",
        "colab_type": "text"
      },
      "source": [
        "# **Homework - for 04/10 class**\n",
        "- 본 notebook파일 (Linear_Regression.ipynb) 의 **가장 마지막 셀**(General Linear Regression - 5. Training) 결과물을 캡처하여 ETL에 제출하여 주세요.\n",
        "- 이때, **plot의 title**을 본인의 \"학번 이름\"으로 달아서 출력해주셔야 합니다. (ex. plt.title('20xx_12345 홍길동') )\n",
        "- 파일 명은 \"학번.jpg\"로 하여 제출해주시면 됩니다. (ex. 2020_12345.jpg)\n",
        "\n",
        "\n"
      ]
    }
  ]
}